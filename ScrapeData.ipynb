{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Pipeline\n",
    "\n",
    "### Extracting: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "import PyPDF2\n",
    "import fitz # PyMuPDF library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sga-ag.de/ergebnisse/katalogarchiv.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the BS object of an html website.\n",
    "def get_html(url):\n",
    "    result = requests.get(url)\n",
    "    return BeautifulSoup(result.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the catalogue Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to define a function to get all the links for the different catalogues and results\n",
    "\n",
    "def get_catalogues_results(html):\n",
    "    boxes_raw = html.find_all(class_=\"tx-reference-teaser normal-layout\")\n",
    "    catalogue_boxes = list(map(lambda x: x.find_all(class_=\"details\"), boxes_raw))\n",
    "    \n",
    "    # initialize an empty dataframe\n",
    "    df = pd.DataFrame(columns=[\"type\", \"dates\", \"catalogue_link\", \"result_link\"])\n",
    "    \n",
    "    # loop through each of the boxes containing the link to the catalogue/results\n",
    "    for i in catalogue_boxes:\n",
    "        box = i[0]\n",
    "        type = box.findNext(\"p\")\n",
    "        dates = box.findNext(\"p\")\n",
    "        catalogue_link = box.findNext(\"a\")\n",
    "        result_link = catalogue_link.findNext(\"a\")\n",
    "        \n",
    "        # append the content of the a and p tags to a dataframe.\n",
    "        df = df.append({\"type\": type.text, \"dates\":dates.text, \"catalogue_link\":catalogue_link[\"href\"], \"result_link\":result_link[\"href\"]}, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_catalogue_links = get_catalogues_results(get_html(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>dates</th>\n",
       "      <th>catalogue_link</th>\n",
       "      <th>result_link</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Herbst-Auktionen</td>\n",
       "      <td>Herbst-Auktionen</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>2012-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sommer-Auktionen</td>\n",
       "      <td>Sommer-Auktionen</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>2012-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Winter-Auktionen</td>\n",
       "      <td>Winter-Auktionen</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>/fileadmin/user_upload/sga-ag.de/ergebnisse/ka...</td>\n",
       "      <td>2012-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type             dates  \\\n",
       "37  Herbst-Auktionen  Herbst-Auktionen   \n",
       "38  Sommer-Auktionen  Sommer-Auktionen   \n",
       "39  Winter-Auktionen  Winter-Auktionen   \n",
       "\n",
       "                                       catalogue_link  \\\n",
       "37  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...   \n",
       "38  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...   \n",
       "39  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...   \n",
       "\n",
       "                                          result_link      id  \n",
       "37  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...  2012-3  \n",
       "38  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...  2012-2  \n",
       "39  /fileadmin/user_upload/sga-ag.de/ergebnisse/ka...  2012-4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the \"id\" column that contains the year (e.g. 21 for 2021) and the auction number (01 for the first of the 4 total auctions in that year)\n",
    "patt = r\"\\d{2,4}[\\-\\_]\\d+\"\n",
    "results_catalogue_links[\"id\"] = results_catalogue_links[\"result_link\"].apply(lambda x: re.findall(patt, x))\n",
    "results_catalogue_links[\"id\"] = results_catalogue_links[\"id\"].apply(lambda x: \"\".join(x))\n",
    "\n",
    "# manually change one value for which there is no id in the link\n",
    "results_catalogue_links.loc[results_catalogue_links[\"id\"] == \"\", \"id\"] = \"2012-3\"\n",
    "\n",
    "# save results to csv\n",
    "results_catalogue_links.to_csv(\"Data\\\\links.csv\")\n",
    "results_catalogue_links.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading PDFs with given Link and creating folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download the PDFs.\n",
    "\n",
    "def download_pdf(url, filename, document_type=None):\n",
    "    pdf = urllib.request.urlopen(url)\n",
    "    \n",
    "    if document_type == None:\n",
    "        raise Exception(\"Is the pdf a result or a catalogue?\")\n",
    "    elif document_type == \"result\":\n",
    "        path = \"Data\\\\results\\\\\"\n",
    "        os.mkdir(\"Data\\\\results\") if \"results\" not in os.listdir(\"Data\") else None\n",
    "    elif document_type == \"catalogue\":\n",
    "        path = \"Data\\\\catalogue\\\\\"\n",
    "        os.mkdir(\"Data\\\\catalogue\") if \"catalogue\" not in os.listdir(\"Data\") else None\n",
    "    \n",
    "    with open(path + filename, \"wb\") as f:\n",
    "        f.write(pdf.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catalogue PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the entire list of links\n",
    "for i in range(len(results_catalogue_links)):\n",
    "    \n",
    "    for j in [\"catalogue_link\", \"result_link\"]:\n",
    "        \n",
    "        # get the link to the website where the PDF is stored\n",
    "        link = \"https://www.sga-ag.de\" + results_catalogue_links.iloc[i][j]\n",
    "        kind = j.split(\"_\")[0]\n",
    "        \n",
    "        # create the file name\n",
    "        file_name = kind + \"_\" + results_catalogue_links.iloc[i][\"id\"] + \".pdf\"\n",
    "        \n",
    "        # download the pdf and write it to the correct path\n",
    "        download_pdf(link, file_name, document_type=j.split(\"_\")[0])\n",
    "        \n",
    "        # print out the progress\n",
    "        print(\"download finished: \", link, file_name)\n",
    "else:\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming: getting information about the auction objects from the raw PDFs\n",
    "\n",
    "Extracting all the information from the PDFs is quite a tedious task.\n",
    "\n",
    "Problems:\n",
    "    - different PDF structure that changed over the years.\n",
    "\n",
    "Some regularities concerning the structure of the docuemnts:\n",
    "\n",
    "- the description for a single auction object always ends with the \"Mindestgebot\"\n",
    "- every auction object starts with \"Lage:\"\n",
    "- besides that the structure of the listings can vary depending on the type of real estate, attributes can be missing.\n",
    "\n",
    "Approach:\n",
    "\n",
    "- split the contents of a page by \"Lage\", since every auction item has this at the beginning of the decription it will seperate the different auction items even if there are multiple ones on one page.\n",
    "\n",
    "- instead of searching for the properties of the objects directly we will split by the attribute resulting in a list with an even number of items\n",
    "\n",
    "- general structure of an offering:\n",
    "    - Location -> Lage >> Grundstücksgröße, Objektbeschreibung\n",
    "    - (Estate Size)\n",
    "    - Object Description >> Energieausweis, Mindestgebot, Fläche\n",
    "    - (living/floor space) \"Wohn-/Nutzfläche\" or \"Wohn-/ Nutzfläche\" or \"Wohnfläche\" or \"Nutzfläche\"\n",
    "    - (Energy Certificate) -> sometimes not available for older offerings \n",
    "    - (Yearly Rent (net or gross))\n",
    "    - (housing benefits) -> \"Wohngeld\"/\"Hausgeld mtl.\"\n",
    "    - Minimal bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finder(pattern, pdf):\n",
    "\n",
    "    res = re.findall(pattern, pdf)\n",
    "    print(res)\n",
    "    if res == []:\n",
    "        return [np.NaN]\n",
    "    else:\n",
    "        return res\n",
    "    \n",
    "def get_pdf_contents(pdf: str, df: pd.DataFrame):\n",
    "\n",
    "    # firstly, seperate the page into the different auction object that might be on it\n",
    "    \n",
    "    # every object begins with \"Lage\", the first value could potentially contain the ID of the auction object\n",
    "    res = re.split(r\"(Lage:)\", pdf)\n",
    "    id_info = res[0]\n",
    "    objects = res[1:]\n",
    "    \n",
    "    # put the objects into a list [description]]\n",
    "    objects = [objects[i*2+1] for i in list(range(0, int(len(objects)/2)))]\n",
    "    \n",
    "    # create the pattern for the split operation\n",
    "    Attributes = [\"Bruttogeschossfläche:\", \"Grundstücksgröße:\", \"Objektbeschreibung:\", \"Lage:\", \"Energieausweis:\" ,\"Nutzfläche:\", \"Hausgeld mtl.:\", \"Mindestgebot:\", \"Wohnfläche:\"]\n",
    "    \n",
    "    # some of the search tags have special regex characters like the \"()\" in \"Jahresmiete (netto)\" we have to therefore manually ad them.\n",
    "    search = \"(\" + \"|\".join(Attributes) + \"|Jahresmiete \\(netto\\):\" + \")\"\n",
    "    split_pattern = re.compile(search)\n",
    "    \n",
    "    Lagen = []\n",
    "    rest_dict = []\n",
    "    \n",
    "    for object in objects:\n",
    "        \n",
    "        split_object = re.split(split_pattern, object)\n",
    "        \n",
    "        rest = split_object[1:]\n",
    "        \n",
    "        d = {rest[i*2]: rest[i*2+1] for i in range(int(len(rest)/2))}\n",
    "        d[\"Lage:\"] = split_object[0]\n",
    "        rest_dict.append(d)\n",
    "        \n",
    "        \n",
    "    df = df.append(rest_dict, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# helper function to get the string of the PDF page and remove extra spaces\n",
    "def pdf_page_as_string(pdf, page: int):\n",
    "        return \" \".join(pdf.getPage(page).extractText().split()).replace(\"- \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the relevant paths where the PDFs are stored\n",
    "paths = os.listdir(path=\"Data\\\\catalogue\")\n",
    "\n",
    "# instantiate a new Pandas Dataframe in which we will store the data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    # if reading of the PDF document fails we will skipp to the next one since that is most likely a problem with the PyPDF2 library for which there is not fix.\n",
    "    try:\n",
    "        pdf_object = open(\"Data\\\\catalogue\\\\\" + path, \"rb\")\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_object)\n",
    "    except:\n",
    "        print(\"Problem Handling Document Number: {}\".format(path))\n",
    "    \n",
    "    print(\"Currently Processing: {}\".format(path))\n",
    "    num_pages = pdf_reader.getNumPages()\n",
    "    \n",
    "    # loop throug all of the pages of the PDF document\n",
    "    for i in range(num_pages):\n",
    "        pdf_string = pdf_page_as_string(pdf_reader, i)\n",
    "        \n",
    "        # append the data gathered from the page to the PDF document.\n",
    "        data = get_pdf_contents(pdf_string, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Data from the \"results\" PDFs\n",
    "\n",
    "Unfortunately, the library PyDF2 did not work with the results PDFs, therefore we will fall back on the PyMuPDF library.\n",
    "\n",
    "The general structure of these results is:\n",
    "\n",
    "- Object Number\n",
    "- City\n",
    "- Adress\n",
    "- Limit Price\n",
    "- Winning bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"Data\\\\results\\\\\" + \"result_18-01.pdf\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc.load_page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25.',\n",
       " 'Eisfeld\\nTraubenwirtsgasse 13\\n1.000,--\\n5.000,--\\n',\n",
       " '26.',\n",
       " 'Gräfenthal\\nProbstzellaer Straße 11-13a\\n125.000,--\\n131.000,--\\n',\n",
       " '27.',\n",
       " 'Oberweißbach\\nFröbelstraße/ Unter dem Kohlwege\\n9.000,--\\n9.010,--\\n',\n",
       " '29.',\n",
       " 'Bleicherode\\nNordhäuser Straße 93\\n9.000,--\\n23.000,--\\n',\n",
       " '30.',\n",
       " 'Saara OT Geißen\\nFlurstück 114\\n90.000,--\\n102.000,--\\n',\n",
       " '31.',\n",
       " 'Stadt Sandersleben (Anhalt)\\nAscherslebener Straße 24\\n25.000,--\\n25.000,--\\n',\n",
       " '32.',\n",
       " 'Mansfeld OT Möllendorf\\nMöllendorfer Dorfstraße 28\\n9.000,--\\n20.500,--\\n',\n",
       " '33.',\n",
       " 'Köthen\\nGeorgstraße 2a-c\\n9.000,--\\n105.000,--\\n',\n",
       " '34.',\n",
       " 'Köthen OT Baasdorf\\nLindenplatz 8\\n12.000,--\\n20.000,--\\n',\n",
       " '35.',\n",
       " 'Muldestausee OT Pouch\\nFeldstraße 1\\n49.000,--\\n80.000,--\\n',\n",
       " '36.',\n",
       " 'Burg\\nMarkt 20\\n25.000,--\\n39.000,--\\n',\n",
       " '37.',\n",
       " 'Oschersleben OT Schmercke\\nAm Jungfernhölzchen 7, 8, 9, 10 und 11\\n15.000,--\\n15.000,--\\n',\n",
       " '38.',\n",
       " 'Kriebitzsch\\nKurze Straße\\n1.000,--\\n2.000,--\\n',\n",
       " '39.',\n",
       " 'Hecklingen OT Schneidlingen\\nAm Bahnhof\\n3.000,--\\n11.500,--\\n',\n",
       " '40.',\n",
       " 'Sonnenstein OT Zwinge\\nL 2012 (Flst. 232/1)\\n500,--\\n500,--\\n',\n",
       " '41.',\n",
       " 'Langenwetzendorf OT Naitschau\\nNaitschau 10\\n3.000,--\\n4.000,--\\n',\n",
       " '42.',\n",
       " 'Greiz\\nLindenstraße 40\\n2.500,--\\n7.000,--\\n',\n",
       " '43.',\n",
       " 'Lindenkreuz OT Rothenbach\\nFlste. 190/1, 305\\n500,--\\n800,--\\n',\n",
       " '44.',\n",
       " 'Schwerstedt\\nButtelstedter Straße, Flst. 505/36\\n5.000,--\\n14.000,--\\n',\n",
       " '45.',\n",
       " 'Gebesee\\nTheo-Neubauer-Straße, Flst. 203/96\\n2.000,--\\n7.500,--\\nSeite 2\\n']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patt = r\"(\\d{1,2}\\.)\\n\"\n",
    "# for i in re.split(patt, page.get_text()):\n",
    "#     print(i)\n",
    "#     \n",
    "    \n",
    "re.split(patt, page.get_text())[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Save results to a MongoDB database\n",
    "\n",
    "We want to have a flexible schema that depends on how many attributes we find for a given auction object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_object = open(\"Data\\\\results\\\\\" + \"result_18-01.pdf\", \"rb\")\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pdf_reader.getPage(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RectangleObject([0, 0, 595, 842])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.mediaBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93ff2fb3ab55f45baf9b992255903249eaebee6bb8e37ed653eb50e096a7d927"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
